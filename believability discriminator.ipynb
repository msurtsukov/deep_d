{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Input, Embedding, Reshape, MaxPooling1D, Conv1D\n",
    "from keras.layers import LSTM, GRU, Conv1D\n",
    "from keras.layers import Dropout, BatchNormalization, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.activations import sigmoid\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/merged_sampled.json', encoding='utf-8') as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sentences = list(json_data.keys())\n",
    "fake_sentences = []\n",
    "for x in json_data.values():\n",
    "    fake_sentences.extend(x)\n",
    "\n",
    "print('original_sentences:\\t', len(original_sentences))\n",
    "print('fake_sentences:\\t', len(fake_sentences))\n",
    "\n",
    "print('mean len of original sentences:\\t', np.mean([len(x) for x in original_sentences]), 'chars')\n",
    "print('mean len of fake sentences:\\t', np.mean([len(x) for x in fake_sentences]), 'chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.utils import load_transformer\n",
    "\n",
    "transformer = load_transformer('models/shm_c3')\n",
    "\n",
    "chars = transformer.tokens\n",
    "char_cats = len(chars)\n",
    "print('total chars:', char_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.hist([len(x) for x in original_sentences], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.hist([len(x) for x in fake_sentences], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs.utils import pad\n",
    "\n",
    "# transform text into sequence of indices\n",
    "pad_idx = char_cats\n",
    "original_indexes = np.array([pad(transformer.transform(sent), max_len, pad_idx) for sent in original_sentences])\n",
    "fake_indexes     = np.array([pad(transformer.transform(sent), max_len, pad_idx) for sent in fake_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_batches = (len(original_indexes) + len(fake_indexes)) // 300\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs.utils import split_data_into_correct_batches\n",
    "X, y = split_data_into_correct_batches(original_indexes, fake_indexes, n_batches, max_len, make_equal_folding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "a = plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "def create_cnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats+1, int(char_cats / 1.5))(inp)\n",
    "    x = Conv1D(128, kernel_size=8, activation='relu', padding='same')(v)\n",
    "    x = Dropout(0.3)(BatchNormalization()(x))\n",
    "    x = MaxPooling1D(4, padding='same')(x)\n",
    "\n",
    "    x = Conv1D(256, kernel_size=4, activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.3)(BatchNormalization()(x))\n",
    "    x = MaxPooling1D(5, padding='same')(x)\n",
    "\n",
    "    h = Flatten()(x) # None, 5*256\n",
    "    y = Dense(2, activation='softmax')(h)\n",
    "    model = Model(inp, y, name=\"char_cnn\")\n",
    "    model_to_save = Model(inp, y, 'char_cnn')\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model, model_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn, nn_to_save = create_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import clock\n",
    "\n",
    "n_epochs = 4\n",
    "n_batches = (len(original_indexes) + len(fake_indexes)) // 15\n",
    "\n",
    "lens = [max_len - np.mean([list(x).count(42) for x in fake_indexes])]\n",
    "sizes = [len(fake_indexes)]\n",
    "\n",
    "indexes = None\n",
    "for epoch in range(n_epochs):\n",
    "    if epoch == 0:\n",
    "        X, y = split_data_into_correct_batches(original_indexes, fake_indexes, n_batches, max_len, make_equal_folding=True)\n",
    "    elif epoch % 3 == 0:\n",
    "        t = clock()\n",
    "        probs = nn.predict(fake_indexes)[:, 0]\n",
    "        bool_ind = np.random.uniform(0., 1., probs.shape) < probs\n",
    "        indexes = np.arange(bool_ind.shape[0])[bool_ind]\n",
    "\n",
    "        print('epoch', epoch, '- deleting took', clock() - t, 'sec')\n",
    "        X, y = split_data_into_correct_batches(original_indexes, fake_indexes[indexes], n_batches, max_len, make_equal_folding=True)\n",
    "        lens.append(max_len - np.mean([list(x).count(42) for x in fake_indexes[indexes]]))\n",
    "        sizes.append(len(indexes))\n",
    "    nn.fit(X, y, batch_size=batch_size, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = plt.hist([len(x) for x in original_sentences], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = plt.hist([len(x) for x in fake_sentences[indexes]], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_to_save.save('models/discriminator_believability_rnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
