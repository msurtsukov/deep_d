{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Умеет нормализовать, сохранять тэги и находить именованные сущности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total grammars count: 146\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "from natasha import Combinator, DEFAULT_GRAMMARS\n",
    "\n",
    "# DEFAULT_GRAMMARS содержит стандартный набор правил:\n",
    "# [\n",
    "#    <enum 'Person'>,\n",
    "#    <enum 'Location'>,\n",
    "#    <enum 'Organisation'>,\n",
    "#           ...\n",
    "# ]\n",
    "\n",
    "combinator = Combinator(DEFAULT_GRAMMARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text =  \"\"\"\n",
    " А. Н. Островский.\n",
    "Бедная невеста.\n",
    "Комедия в пяти действиях.\n",
    "ЛИЦА: Анна Петровна Незабудкина, вдова небогатого чиновника.\n",
    "Марья Андреевна, ее дочь.\n",
    "Владимир Васильевич Мерич |} молодые люди, знакомые Незабудкиной.\n",
    "Иван Иванович Милашин |Платон Маркович Добротворский, старый стряпчий.\n",
    "Максим Дорофеевич Беневоленский, чиновник.\n",
    "Арина Егоровна Хорькова, вдова, мещанка.\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list(combinator.extract(text))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "proc_line(text, 0, 0, 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for grammar, tokens in combinator.resolve_matches(combinator.extract(text)):\n",
    "    print(\"Правило:\", grammar)\n",
    "    print(\"Токены:\", tokens)\n",
    "    token = tokens[0]\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "token.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbs = re.compile(r\"[^А-Яа-я:!\\?,\\.\\\"— -]\")\n",
    "clear = re.compile(r\"[ _]{2,}\")\n",
    "punct = re.compile(r\"(\\.\\.\\.|!\\.\\.|\\?\\.\\.|[:!\\?,\\.\\\"—])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def morph_line(line, normalize=True, tag=True, ner=True):\n",
    "    if ner:\n",
    "        for grammar, tokens in combinator.resolve_matches(combinator.extract(line)):\n",
    "            for token in tokens:\n",
    "                start, end = token.position\n",
    "                line = line[:start] + \"@\"*(end-start) + line[end:]\n",
    "#                 line = line.replace(token.value, \"<@>\", 1)\n",
    "\n",
    "    line = re.sub(punct, r\" <\\1>\", line)\n",
    "    words  = line.split(\" \")\n",
    "    if normalize or tag:\n",
    "        parsed = [morph.parse(w)[0] for w in words]\n",
    "        if normalize:\n",
    "            words  = [wparsed.normal_form  for wparsed in parsed]\n",
    "        if tag:\n",
    "            tags   = [wparsed.tag.cyr_repr for wparsed in parsed]\n",
    "\n",
    "        line = '_'.join(words) + ';' + '_'.join(tags)\n",
    "    else:\n",
    "        line = '_'.join(words)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_line(line):\n",
    "    line = re.sub(symbs, \"\", line)\n",
    "    line = re.sub(r\"[ ]+\", \" \", line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_line(line):\n",
    "    line = re.sub(\"@+\", \"<@>\", line)\n",
    "    line = re.sub(clear, \" \", line)\n",
    "    line = re.sub(\"><\", \">_<\", line)\n",
    "    line = line.strip(\"_\")\n",
    "    line = line.strip()\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proc_line(line, normalize=True, tag=True, ner=True):\n",
    "    line = prepare_line(line)\n",
    "    line =   morph_line(line, normalize, tag, ner)\n",
    "    line =   clear_line(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalize = False\n",
    "tag = False\n",
    "ner = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fnin  = \"data/merged_sent_split.txt\"\n",
    "fnout = \"data/merged_punct_tokenize.csv\"\n",
    "\n",
    "# with open(fnin, encoding=\"utf-8\") as fin, open(fnout, \"w\", encoding=\"utf-8\") as fout:\n",
    "#     for i, line in enumerate(fin.readlines()):\n",
    "#         pline = proc_line(line, normalize, tag, ner)\n",
    "#         print(pline, file=fout, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def worker(line_t):\n",
    "    return proc_line(line_t, normalize, tag, ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done126 / 2126493\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "p = Pool(8)\n",
    "\n",
    "with open(fnin, encoding=\"utf-8\") as fin:\n",
    "    lines = fin.readlines()\n",
    "\n",
    "\n",
    "with open(fnout, \"w\", encoding=\"utf-8\") as fout:\n",
    "    l = len(lines)\n",
    "    step = l // 1000\n",
    "    for i in range(0, l + step, step):\n",
    "        plines = p.map(worker, lines[i:i+step])\n",
    "        print(i, \"/\", l, end=\"\\r\")\n",
    "        for pline in plines:\n",
    "            print(pline, file=fout, sep='')\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
