{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Input, Embedding, Reshape\n",
    "from keras.layers import LSTM, GRU, Conv1D\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.activations import sigmoid\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_non_dostoewskij_text():\n",
    "    dostoewskij_names = []\n",
    "    folder = 'data/Русская литература/Достоевский Ф.М.'\n",
    "    for item in os.listdir(folder):\n",
    "        itempath = os.path.join(folder, item)\n",
    "        #print(item)\n",
    "        if os.path.isfile(itempath):\n",
    "            dostoewskij_names.append(item.replace('.zip', ''))\n",
    "    res = ''\n",
    "    folder = 'data/texts/'\n",
    "    for item in os.listdir(folder):\n",
    "        itempath = os.path.join(folder, item)\n",
    "        if os.path.isfile(itempath) and not(item.replace('.txt', '') in dostoewskij_names):\n",
    "            with open(itempath, encoding='utf-8') as f:\n",
    "                res += f.read()\n",
    "    return res\n",
    "\n",
    "with open('data/dostoewskij_sent_split.txt', encoding='utf-8') as f:\n",
    "    dostoewskij_text = f.read().lower()\n",
    "non_dostoewskij_text = get_non_dostoewskij_text()\n",
    "\n",
    "with open('data/non_dostoewskij_texts.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(non_dostoewskij_text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def clear_text_from_rare_chars(whole_text, delete_enters = False):\n",
    "    whole_text = whole_text.replace('\\t', ' ')\n",
    "    whole_text = whole_text.replace('\\x15', '\\n')\n",
    "    whole_text = whole_text.replace('$', 'з')\n",
    "    whole_text = whole_text.replace('<', '')\n",
    "    whole_text = whole_text.replace('>', '')\n",
    "    whole_text = whole_text.replace('+-', 'е')\n",
    "    whole_text = whole_text.replace('\\\\', '.')\n",
    "    whole_text = whole_text.replace('~', ' ')\n",
    "    whole_text = whole_text.replace('\\x7f', ' ')\n",
    "    whole_text = whole_text.replace('\\xa0', ' ')\n",
    "    whole_text = whole_text.replace('\\xad', '')\n",
    "    whole_text = whole_text.replace('¤', 'О')\n",
    "    whole_text = whole_text.replace('¦', 'е')\n",
    "    whole_text = whole_text.replace('§', '')\n",
    "    whole_text = whole_text.replace('¶', '\\'')\n",
    "    whole_text = whole_text.replace('·', ' ')\n",
    "    whole_text = whole_text.replace('•', ' ')\n",
    "    if delete_enters:\n",
    "        whole_text = whole_text.replace('\\n', ' ')\n",
    "    while '  ' in whole_text:\n",
    "        whole_text = whole_text.replace('  ', ' ')\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_raw_into_sentences(text):\n",
    "    symbs = re.compile(r\"[^А-Яа-я:!\\?,\\.\\\"— - \\n]\")\n",
    "    text = re.sub(symbs, \"\", text)\n",
    "\n",
    "    text = re.sub(r'\\*|\\x01|\\xa0|--|\\t|\"|(\\[.*\\])', \"\", text)\n",
    "    text = re.sub(r'[A-Za-z]+[!.,;:\\-?]*', \"\", text)\n",
    "    text = re.sub(r\"\\n[ ]+\", \"\\n\", text)\n",
    "    text = re.sub(r\"[ ]+\", \" \", text)\n",
    "    text = re.sub(r'(?<=[А-Яа-я,;:\\—\" ])\\n(?=[а-яPS])', r\" \", text)\n",
    "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "    text = re.sub(r\"(?<=[А-Яа-я])[ ]*\\n\", r\".\\n\", text)\n",
    "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "    text = re.sub(r\"\\n(?! \\— [а-я])\", \"\", text)\n",
    "    text = re.sub(r\"([!?.,:;]+)(?=[А-Яа-я])\", r\"\\1 \", text)\n",
    "    text = re.sub(\n",
    "        r\"(?<!\\W[А-Я]\\.)(?<!\\WP\\.)(?<!\\WP\\. S\\.)(?<!\\W(т|Т)\\.)(?<!\\W(т|Т)\\. (к|К|д|Д)\\.)(?<=\\.|\\?|\\!)(?! [а-я])(?! \\— [а-я])\\s\",\n",
    "        \"\\n\", text)\n",
    "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "    text = re.sub(r\";\", \",\", text)\n",
    "    text = re.sub(r\"\\—(?=.)\", \"— \", text)\n",
    "    text = re.sub(r\"([!?.,:;]+)(?=[А-Яа-я])\", r\"\\1 \", text)\n",
    "    text = re.sub(r\"(?<=[!?.,:;])\\—\", \" —\", text)\n",
    "    text = re.sub(r\"\\.{4,}\", \"\", text)\n",
    "    text = re.sub(r\"\\s\\.\\s\", \"\\n\", text)\n",
    "    text = re.sub(r\"(?<=[!.,?:;])P.\", \"\\nP.\", text)\n",
    "    text = re.sub(r\"(?<=[!.,?:;])\\— (?![а-я])\", \"\\n—\", text)\n",
    "    text = re.sub(\n",
    "        r\"(?<!\\W[А-Я]\\.)(?<!\\WP\\.)(?<!\\WP\\. S\\.)(?<!\\W(т|Т)\\.)(?<!\\W(т|Т)\\. (к|К|д|Д)\\.)(?<=\\.|\\?|\\!)(?! [а-я])(?! \\— [а-я])\\s\",\n",
    "        \"\\n\", text)\n",
    "    text = re.sub(r\"(?<=[!?.,:;])\\n\\— (?=[а-я])\", \" — \", text)\n",
    "    text = re.sub(r\"\\([\\d]*\\)\", \"\", text)\n",
    "    text = re.sub(r\"(\\.\\n){2,}\", \"\\n\", text)\n",
    "    text = re.sub(r\"[IXV]+\", r\"\", text)\n",
    "    text = re.sub(r\"\\s\\.\\s\", \"\\n\", text)\n",
    "    text = re.sub(r\"\\s([!?.,:;])\", \"\\1\", text)\n",
    "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "    text = re.sub(r\"\\n[ ]+\", \"\\n\", text)\n",
    "    text = re.sub(r\"[ ]+\", \" \", text)\n",
    "    text = re.sub(r\"(?<=[!?.,:;])\\n\\— (?=[а-я])\", \" — \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs.utils import text_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dostoewskij_length:\t 4967030\n",
      "non_dostoewskij_length:\t 175060228\n"
     ]
    }
   ],
   "source": [
    "with open('data/dostoewskij.txt', encoding='utf-8') as f:\n",
    "    dostoewskij_text = f.read().lower()\n",
    "with open('data/non_dostoewskij_texts.txt', encoding='utf-8') as f:\n",
    "    non_dostoewskij_text = f.read().lower()\n",
    "\n",
    "sentenced_dostoewskij = split_raw_into_sentences(dostoewskij_text)\n",
    "sentenced_non_dostoewskij = split_raw_into_sentences(non_dostoewskij_text)\n",
    "\n",
    "sentenced_dostoewskij = text_preprocess(sentenced_dostoewskij)\n",
    "sentenced_non_dostoewskij = text_preprocess(sentenced_non_dostoewskij)\n",
    "\n",
    "dostoewskij_sentences = sentenced_dostoewskij.split('\\n')\n",
    "non_dostoewskij_sentences = sentenced_non_dostoewskij.split('\\n')\n",
    "\n",
    "#dostoewskij_text = clear_text_from_rare_chars(dostoewskij_text, delete_enters=True)\n",
    "#non_dostoewskij_text = clear_text_from_rare_chars(non_dostoewskij_text, delete_enters=True)\n",
    "\n",
    "print('dostoewskij_length:\\t', len(dostoewskij_text))\n",
    "print('non_dostoewskij_length:\\t', len(non_dostoewskij_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "s = set(sentenced_dostoewskij)\n",
    "print(len(s))\n",
    "s2 = set(sentenced_non_dostoewskij)\n",
    "print(len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 42\n"
     ]
    }
   ],
   "source": [
    "from libs.utils import load_transformer\n",
    "\n",
    "transformer = load_transformer('models/shm_c1')\n",
    "\n",
    "chars = transformer.tokens\n",
    "char_cats = len(chars)\n",
    "print('total chars:', char_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "едоразвитой и вовсе не \n",
      "\n",
      "учащейся молодежи\". не знаю, что именно хотел доказать этим вывертом собственно \n",
      "\n",
      "автор статейки \"русского мира\": хотел ли он польстить учащейся молодежи? или, \n",
      "\n",
      "напротив, хитрым маневром и, так сказать, в виде ласкательства думал ее же \n",
      "\n",
      "поднадуть немного, но только с самыми почтенными целями, - то есть для ее же \n",
      "\n",
      "пользы, - и для достижения цели употребил столь известный прием гувернанток и \n",
      "\n",
      "нянюшек с маленькими ребятками: вот, дескать, милые дети, видите, какие те \n",
      "\n",
      "нехорошие буяны, кричат и дерутся, и их непременно высекут за то, что они такие \n",
      "\n",
      "\"недоразвитки\"; вы же вот такие милые хваленые паиньки, за столом сидите прямо, \n",
      "\n",
      "ножками под столом не болтаете, и вам за это непременно гостинцу дадут. или, \n",
      "\n",
      "наконец, просто-запросто автору захотелось \"защитить\" нашу учащуюся молодежь \n",
      "\n",
      "перед правительством и употребить для сего прием, который сам он, может быть, \n",
      "\n",
      "считает необыкновенно хитрым и тонким? \n",
      "\n",
      "прямо скажу: хотя я поставил все эти вопросы, но личные пели \n",
      "\n",
      "автора статейки \"русского мира\" не возбуждают во мне ни малейшего любопытства. и \n",
      "\n",
      "даже, чтоб оговориться окончательно, прибавлю, что ложь и старый приевшийся \n",
      "\n",
      "выверт выраженной \"русским миром\" мысли я наклонен считать в настоящем случае \n",
      "\n",
      "чем-то неумышленным и нечаянным, то есть что сам автор статейки совершенно \n",
      "\n",
      "поверил словам своим и принял их за правду с тем высшим простодушием, которое \n",
      "\n",
      "так похвально и даже трогательно по своей беззащитности во всяком другом случае. \n",
      "\n",
      "но кроме того, что ложь, принятая за правду, имеет всегда самый опасный вид \n",
      "\n",
      "(несмотря даже. на то, что является в \"русском мире\"), - кроме того, бросается в \n",
      "\n",
      "глаза и то, что никогда еще не являлась она в столь обнаженном, точном и \n",
      "\n",
      "безыскусственном виде, как в этой статейке. подлинно, заставь иного человека \n",
      "\n",
      "молиться богу, и он лоб расшибет. вот в этом-то виде и любопытно проследить эту \n",
      "\n",
      "ложь и вывести ее на свет по возможности, ибо когда-то еще дождешься в другой \n",
      "\n",
      "раз такой безыскусственной откровенн\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ая на светлую точку бомбы, которая, светлее и светлее, быстрее и быстрее приближаясь, шлепнулась около траншеи, он только немного и невольно, под влиянием испуганного крика, нагнул голову и пошел дальше. \n",
      "    - вишь, какой бравый! - сказал матрос, который преспокойно смотрел на падавшую бомбу и опытным глазом сразу расчел, что осколки ее не могут задеть в траншее, - и ложиться не хочет. \n",
      "    уже несколько шагов только оставалось калугину перейти через площадку до блиндажа командира бастиона, как опять на него нашло затмение и этот глупый страх; сердце забилось сильнее, кровь хлынула в голову, и ему нужно было усилие над собою, чтобы пробежать до блиндажа. \n",
      "    - что вы так запыхались? - сказал генерал, когда он ему передал приказания. \n",
      "    - шел скоро очень, ваше превосходительство! \n",
      "    - не хотите ли вина стакан? \n",
      "    калугин выпил стакан вина и закурил папиросу. дело уже прекратилось, только сильная канонада продолжалась с обеих сторон. в блиндаже сидел генерал n., командир бастиона и еще человек шесть офицеров, в числе которых был и праскухин, и говорили про разные подробности дела. сидя в этой уютной комнатке, обитой голубыми обоями, с диваном, кроватью, столом, на котором лежат бумаги, стенными часами и образом, перед которым горит лампадка, глядя на эти признаки жилья и на толстые аршинные балки, составлявшие потолок, и слушая выстрелы, казавшиеся слабыми в блиндаже, калугин решительно понять не мог, как он два раза позволил себя одолеть такой непростительной слабости; он сердился на себя, и ему хотелось опасности, чтобы снова испытать себя. \n",
      "    - а вот я рад, что и вы здесь, капитан, - сказал он морскому офицеру в штаб-офицерской шинели, с большими усами и георгием, который вошел в это время в блиндаж и просил генерала дать ему рабочих, чтобы исправить на его батарее две амбразуры, которые были засыпаны. - мне генерал приказал узнать, - продолжал калугин, когда командир батареи перестал говорить с генералом, - могут ли ваши орудия стрелять по траншее картеч\n"
     ]
    }
   ],
   "source": [
    "print_len = 2000\n",
    "pos = np.random.randint(len(dostoewskij_text))\n",
    "print(dostoewskij_text[pos:pos+print_len])\n",
    "print('-' * 100)\n",
    "pos = np.random.randint(len(non_dostoewskij_text))\n",
    "print(non_dostoewskij_text[pos:pos+print_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_batches = len(dostoewskij_text) // 3000\n",
    "batch_size = 16\n",
    "#n_batches -= n_batches % batch_size\n",
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs.utils import pad\n",
    "\n",
    "# transform text into sequence of indices\n",
    "pad_idx = char_cats\n",
    "dostoewskij_indexes     = np.array([pad(transformer.transform(sent), max_len, pad_idx) for sent in dostoewskij_sentences])\n",
    "non_dostoewskij_indexes = np.array([pad(transformer.transform(sent), max_len, pad_idx) for sent in non_dostoewskij_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data_into_correct_batches_sentences(text1_indexes, text2_indexes, make_equal_folding = True):\n",
    "    prime_number = 2147483647\n",
    "    \n",
    "    X = np.zeros((n_batches, max_len), dtype=np.int64)\n",
    "    Y = np.zeros((n_batches,), dtype=np.int64)\n",
    "    \n",
    "    choose_from_first = True\n",
    "    index1 = 0\n",
    "    index2 = 0\n",
    "    for i in range(n_batches):\n",
    "        if make_equal_folding:\n",
    "            if choose_from_first:\n",
    "                index1 = (index1 + prime_number) % (len(text1_indexes))\n",
    "                X[i, :] = text1_indexes[index1]\n",
    "                Y[i] = 0\n",
    "            else:\n",
    "                index2 = (index2 + prime_number) % (len(text2_indexes))\n",
    "                X[i, :] = text2_indexes[index2]\n",
    "                Y[i] = 1\n",
    "                \n",
    "            choose_from_first = not choose_from_first\n",
    "        else:\n",
    "            index1 = (index1 + prime_number) % (len(text1_indexes) + len(text2_indexes))\n",
    "            if index1 < len(text1_indexes) - max_len + 1:\n",
    "                X[i, :] = text1_indexes[index1]\n",
    "                Y[i] = 0\n",
    "            else:\n",
    "                index2 = index1 - (len(text1_indexes))\n",
    "                X[i, :] = text2_indexes[index2]\n",
    "                Y[i] = 1\n",
    "    return X, Y\n",
    "\n",
    "X, y = split_data_into_correct_batches_sentences(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (200,200) into shape (200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-155355ab66cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data_into_correct_batches_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdostoewskij_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_dostoewskij_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_equal_folding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-155355ab66cf>\u001b[0m in \u001b[0;36msplit_data_into_correct_batches_raw\u001b[0;34m(text1_indexes, text2_indexes, make_equal_folding)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchoose_from_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mindex1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprime_number\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext1_indexes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext1_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (200,200) into shape (200)"
     ]
    }
   ],
   "source": [
    "def split_data_into_correct_batches_raw(text1_indexes, text2_indexes, make_equal_folding = True):\n",
    "    prime_number = 2147483647\n",
    "    \n",
    "    X = np.zeros((n_batches, max_len), dtype=np.int64)\n",
    "    Y = np.zeros((n_batches,), dtype=np.int64)\n",
    "    \n",
    "    choose_from_first = True\n",
    "    index1 = 0\n",
    "    index2 = 0\n",
    "    for i in range(n_batches):\n",
    "        if make_equal_folding:\n",
    "            if choose_from_first:\n",
    "                index1 = (index1 + prime_number) % (len(text1_indexes) - max_len + 1)\n",
    "                X[i, :] = text1_indexes[index1:index1+max_len]\n",
    "                Y[i] = 0\n",
    "            else:\n",
    "                index2 = (index2 + prime_number) % (len(text2_indexes) - max_len + 1)\n",
    "                X[i, :] = text2_indexes[index2:index2+max_len]\n",
    "                Y[i] = 1\n",
    "                \n",
    "            choose_from_first = not choose_from_first\n",
    "        else:\n",
    "            index1 = (index1 + prime_number) % (len(text1_indexes) + len(text2_indexes) - 2*max_len + 2)\n",
    "            if index1 < len(text1_indexes) - max_len + 1:\n",
    "                X[i, :] = text1_indexes[index1:index1 + max_len]\n",
    "                Y[i] = 0\n",
    "            else:\n",
    "                index2 = index1 - (len(text1_indexes) - max_len + 1)\n",
    "                X[i, :] = text2_indexes[index2:index2 + max_len]\n",
    "                Y[i] = 1\n",
    "    return X, Y\n",
    "\n",
    "X, y = split_data_into_correct_batches_raw(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "a = plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_char_rnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = GRU(256, stateful=False, return_sequences=True, unroll=True, implementation=0)(v)\n",
    "    h2 = GRU(256, stateful=False, return_sequences=False, unroll=True, implementation=0)(h1)\n",
    "    y = Dense(2, activation='softmax')(h2)\n",
    "    model = Model(inp, y, name=\"char_rnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = create_char_rnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tb = TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = rnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1)#, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 8\n",
    "histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(rnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.save('models/discriminator_style_rnn_model.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_char_cnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = Conv1D(filters=256, kernel_size=5, strides=2, activation='relu')(v)\n",
    "    h2 = Conv1D(filters=128, kernel_size=5, strides=2, activation='relu')(h1)\n",
    "    h3 = Conv1D(filters=64, kernel_size=5, strides=2, activation='relu')(h2)\n",
    "    r = Reshape((-1,))(h3)\n",
    "    y = Dense(2, activation='softmax')(r)\n",
    "    model = Model(inp, y, name=\"char_cnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnn = create_char_cnn()\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "history = cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1)#, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_epochs = 8\n",
    "n_batches = len(dostoewskij_indexes) // 30\n",
    "cnn_histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_epochs = 8\n",
    "cnn_histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_char_cnn_rnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = Conv1D(filters=256, kernel_size=3, strides=1, activation=sigmoid)(v)\n",
    "    h2 = GRU(256, stateful=False, return_sequences=True, unroll=True, implementation=0)(h1)\n",
    "    h3 = GRU(256, stateful=False, return_sequences=False, unroll=True, implementation=0)(h2)\n",
    "    y = Dense(2, activation='softmax')(h3)\n",
    "    model = Model(inp, y, name=\"char_cnn_rnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
