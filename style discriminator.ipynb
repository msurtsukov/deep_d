{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Input, Embedding, Reshape, MaxPooling1D, Conv1D\n",
    "from keras.layers import LSTM, GRU, Conv1D\n",
    "from keras.layers import Dropout, BatchNormalization, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.activations import sigmoid\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from libs.utils import text_preprocess\n",
    "from libs.text_utils import split_raw_into_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/checkov/input.txt', encoding='utf-8') as f:\n",
    "    sentenced_dostoewskij = text_preprocess(f.read())\n",
    "with open('data/checkov/non_checkov_texts.txt', encoding='utf-8') as f:\n",
    "    non_dostoewskij_text = f.read()\n",
    "    \n",
    "sentenced_non_dostoewskij = split_raw_into_sentences(non_dostoewskij_text)\n",
    "sentenced_non_dostoewskij = text_preprocess(sentenced_non_dostoewskij)\n",
    "\n",
    "dostoewskij_sentences = sentenced_dostoewskij.split('\\n')\n",
    "non_dostoewskij_sentences = sentenced_non_dostoewskij.split('\\n')\n",
    "\n",
    "#dostoewskij_text = clear_text_from_rare_chars(dostoewskij_text, delete_enters=True)\n",
    "#non_dostoewskij_text = clear_text_from_rare_chars(non_dostoewskij_text, delete_enters=True)\n",
    "\n",
    "print('dostoewskij_length:\\t', len(sentenced_dostoewskij))\n",
    "print('non_dostoewskij_length:\\t', len(sentenced_non_dostoewskij))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set(sentenced_dostoewskij)\n",
    "print(len(s))\n",
    "s2 = set(sentenced_non_dostoewskij)\n",
    "print(len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.utils import load_transformer\n",
    "\n",
    "transformer = load_transformer('models/shm_c1')\n",
    "\n",
    "chars = transformer.tokens\n",
    "char_cats = len(chars)\n",
    "print('total chars:', char_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "n_batches = len(dostoewskij_sentences) // batch_size\n",
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.utils import pad\n",
    "\n",
    "# transform text into sequence of indices\n",
    "pad_idx = char_cats\n",
    "dostoewskij_indexes     = np.array([pad(transformer.transform(sent), max_len, pad_idx) for sent in dostoewskij_sentences])\n",
    "non_dostoewskij_indexes = np.array([pad(transformer.transform(sent), max_len, pad_idx) for sent in non_dostoewskij_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs.utils import split_data_into_correct_batches\n",
    "X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, \n",
    "                                       n_batches, max_len, make_equal_folding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "a = plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_char_rnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = GRU(256, stateful=False, return_sequences=True, unroll=True, implementation=0)(v)\n",
    "    h2 = GRU(256, stateful=False, return_sequences=False, unroll=True, implementation=0)(h1)\n",
    "    y = Dense(2, activation='softmax')(h2)\n",
    "    model = Model(inp, y, name=\"char_rnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats+1, int(char_cats / 1.5))(inp)\n",
    "    x = Conv1D(128, kernel_size=8, activation='relu', padding='same')(v)\n",
    "    x = Dropout(0.3)(BatchNormalization()(x))\n",
    "    x = MaxPooling1D(4, padding='same')(x)\n",
    "\n",
    "    x = Conv1D(256, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.3)(BatchNormalization()(x))\n",
    "    x = MaxPooling1D(5, padding='same')(x)\n",
    "\n",
    "    h = Flatten()(x)\n",
    "    y = Dense(2, activation='softmax')(h)\n",
    "    model = Model(inp, y, name=\"char_cnn\")\n",
    "    model_to_save = Model(inp, y, name='char_cnn_saved') # no optimizer\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model, model_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn, nn_to_save = create_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    nn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=n_epochs, validation_split=0.33, initial_epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_to_save.save('models/discriminator_style_rnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
