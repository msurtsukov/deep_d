{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Input, Embedding, Reshape\n",
    "from keras.layers import LSTM, GRU, Conv1D\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.activations import sigmoid\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_non_dostoewskij_text():\n",
    "    dostoewskij_names = []\n",
    "    folder = 'data/Русская литература/Достоевский Ф.М.'\n",
    "    for item in os.listdir(folder):\n",
    "        itempath = os.path.join(folder, item)\n",
    "        #print(item)\n",
    "        if os.path.isfile(itempath):\n",
    "            dostoewskij_names.append(item.replace('.zip', ''))\n",
    "    res = ''\n",
    "    folder = 'data/texts/'\n",
    "    for item in os.listdir(folder):\n",
    "        itempath = os.path.join(folder, item)\n",
    "        if os.path.isfile(itempath) and not(item.replace('.txt', '') in dostoewskij_names):\n",
    "            with open(itempath, encoding='utf-8') as f:\n",
    "                res += f.read()\n",
    "    return res\n",
    "\n",
    "with open('data/dostoewskij_sent_split.txt', encoding='utf-8') as f:\n",
    "    dostoewskij_text = f.read().lower()\n",
    "non_dostoewskij_text = get_non_dostoewskij_text()\n",
    "\n",
    "with open('data/non_dostoewskij_texts.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(non_dostoewskij_text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def clear_text_from_rare_chars(whole_text, delete_enters = False):\n",
    "    whole_text = whole_text.replace('\\t', ' ')\n",
    "    whole_text = whole_text.replace('\\x15', '\\n')\n",
    "    whole_text = whole_text.replace('$', 'з')\n",
    "    whole_text = whole_text.replace('<', '')\n",
    "    whole_text = whole_text.replace('>', '')\n",
    "    whole_text = whole_text.replace('+-', 'е')\n",
    "    whole_text = whole_text.replace('\\\\', '.')\n",
    "    whole_text = whole_text.replace('~', ' ')\n",
    "    whole_text = whole_text.replace('\\x7f', ' ')\n",
    "    whole_text = whole_text.replace('\\xa0', ' ')\n",
    "    whole_text = whole_text.replace('\\xad', '')\n",
    "    whole_text = whole_text.replace('¤', 'О')\n",
    "    whole_text = whole_text.replace('¦', 'е')\n",
    "    whole_text = whole_text.replace('§', '')\n",
    "    whole_text = whole_text.replace('¶', '\\'')\n",
    "    whole_text = whole_text.replace('·', ' ')\n",
    "    whole_text = whole_text.replace('•', ' ')\n",
    "    if delete_enters:\n",
    "        whole_text = whole_text.replace('\\n', ' ')\n",
    "    while '  ' in whole_text:\n",
    "        whole_text = whole_text.replace('  ', ' ')\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.utils import text_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dostoewskij.txt', encoding='utf-8') as f:\n",
    "    dostoewskij_text = f.read().lower()\n",
    "with open('data/non_dostoewskij_texts.txt', encoding='utf-8') as f:\n",
    "    non_dostoewskij_text = f.read().lower()\n",
    "\n",
    "dostoewskij_text = text_preprocess(dostoewskij_text)\n",
    "non_dostoewskij_text = text_preprocess(non_dostoewskij_text)\n",
    "\n",
    "# dostoewskij_text = clear_text_from_rare_chars(dostoewskij_text, delete_enters=True)\n",
    "# non_dostoewskij_text = clear_text_from_rare_chars(non_dostoewskij_text, delete_enters=True)\n",
    "\n",
    "print('dostoewskij_length:\\t', len(dostoewskij_text))\n",
    "print('non_dostoewskij_length:\\t', len(non_dostoewskij_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs.utils import load_transformer\n",
    "\n",
    "transformer = load_transformer('models/shm_c1')\n",
    "\n",
    "chars = transformer.tokens\n",
    "char_cats = len(chars)\n",
    "print('total chars:', char_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_len = 2000\n",
    "pos = np.random.randint(len(dostoewskij_text))\n",
    "print(dostoewskij_text[pos:pos+print_len])\n",
    "print('-' * 100)\n",
    "pos = np.random.randint(len(non_dostoewskij_text))\n",
    "print(non_dostoewskij_text[pos:pos+print_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = len(dostoewskij_text) // 3000\n",
    "batch_size = 16\n",
    "#n_batches -= n_batches % batch_size\n",
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform text into sequence of indices\n",
    "original_indexes        = [transformer.transform(sent) for sent in original_sentences]\n",
    "non_dostoewskij_indexes = [transformer.transform(sent) for sent in non_dostoewskij_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_into_correct_batches(text1_indexes, text2_indexes, make_equal_folding = True):\n",
    "    prime_number = 2147483647\n",
    "    \n",
    "    X = np.zeros((n_batches, max_len), dtype=np.int64)\n",
    "    Y = np.zeros((n_batches,), dtype=np.int64)\n",
    "    \n",
    "    choose_from_first = True\n",
    "    index1 = 0\n",
    "    index2 = 0\n",
    "    for i in range(n_batches):\n",
    "        if make_equal_folding:\n",
    "            if choose_from_first:\n",
    "                index1 = (index1 + prime_number) % (len(text1_indexes) - max_len + 1)\n",
    "                X[i, :] = text1_indexes[index1:index1+max_len]\n",
    "                Y[i] = 0\n",
    "            else:\n",
    "                index2 = (index2 + prime_number) % (len(text2_indexes) - max_len + 1)\n",
    "                X[i, :] = text2_indexes[index2:index2+max_len]\n",
    "                Y[i] = 1\n",
    "                \n",
    "            choose_from_first = not choose_from_first\n",
    "        else:\n",
    "            index1 = (index1 + prime_number) % (len(text1_indexes) + len(text2_indexes) - 2*max_len + 2)\n",
    "            if index1 < len(text1_indexes) - max_len + 1:\n",
    "                X[i, :] = text1_indexes[index1:index1 + max_len]\n",
    "                Y[i] = 0\n",
    "            else:\n",
    "                index2 = index1 - (len(text1_indexes) - max_len + 1)\n",
    "                X[i, :] = text2_indexes[index2:index2 + max_len]\n",
    "                Y[i] = 1\n",
    "    return X, Y\n",
    "\n",
    "X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "a = plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_char_rnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = GRU(256, stateful=False, return_sequences=True, unroll=True, implementation=0)(v)\n",
    "    h2 = GRU(256, stateful=False, return_sequences=False, unroll=True, implementation=0)(h1)\n",
    "    y = Dense(2, activation='softmax')(h2)\n",
    "    model = Model(inp, y, name=\"char_rnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = create_char_rnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tb = TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = rnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1)#, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 8\n",
    "histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(rnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.save('models/discriminator_style_rnn_model.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_char_cnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = Conv1D(filters=256, kernel_size=5, strides=2, activation='relu')(v)\n",
    "    h2 = Conv1D(filters=128, kernel_size=5, strides=2, activation='relu')(h1)\n",
    "    h3 = Conv1D(filters=64, kernel_size=5, strides=2, activation='relu')(h2)\n",
    "    r = Reshape((-1,))(h3)\n",
    "    y = Dense(2, activation='softmax')(r)\n",
    "    model = Model(inp, y, name=\"char_cnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnn = create_char_cnn()\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "history = cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1)#, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_epochs = 8\n",
    "n_batches = len(dostoewskij_indexes) // 30\n",
    "cnn_histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_epochs = 8\n",
    "cnn_histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_char_cnn_rnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = Conv1D(filters=256, kernel_size=3, strides=1, activation=sigmoid)(v)\n",
    "    h2 = GRU(256, stateful=False, return_sequences=True, unroll=True, implementation=0)(h1)\n",
    "    h3 = GRU(256, stateful=False, return_sequences=False, unroll=True, implementation=0)(h2)\n",
    "    y = Dense(2, activation='softmax')(h3)\n",
    "    model = Model(inp, y, name=\"char_cnn_rnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
