{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Input, Embedding, Reshape, MaxPooling1D, Conv1D\n",
    "from keras.layers import LSTM, GRU, Conv1D\n",
    "from keras.layers import Dropout, BatchNormalization, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.activations import sigmoid\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from libs.text_utils import split_raw_into_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs.utils import text_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dostoewskij_length:\t 4967030\n",
      "non_dostoewskij_length:\t 175060228\n"
     ]
    }
   ],
   "source": [
    "with open('data/dostoewskij.txt', encoding='utf-8') as f:\n",
    "    dostoewskij_text = f.read().lower()\n",
    "with open('data/non_dostoewskij_texts.txt', encoding='utf-8') as f:\n",
    "    non_dostoewskij_text = f.read().lower()\n",
    "\n",
    "sentenced_dostoewskij = split_raw_into_sentences(dostoewskij_text)\n",
    "sentenced_non_dostoewskij = split_raw_into_sentences(non_dostoewskij_text)\n",
    "\n",
    "sentenced_dostoewskij = text_preprocess(sentenced_dostoewskij)\n",
    "sentenced_non_dostoewskij = text_preprocess(sentenced_non_dostoewskij)\n",
    "\n",
    "dostoewskij_sentences = sentenced_dostoewskij.split('\\n')\n",
    "non_dostoewskij_sentences = sentenced_non_dostoewskij.split('\\n')\n",
    "\n",
    "#dostoewskij_text = clear_text_from_rare_chars(dostoewskij_text, delete_enters=True)\n",
    "#non_dostoewskij_text = clear_text_from_rare_chars(non_dostoewskij_text, delete_enters=True)\n",
    "\n",
    "print('dostoewskij_length:\\t', len(dostoewskij_text))\n",
    "print('non_dostoewskij_length:\\t', len(non_dostoewskij_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "s = set(sentenced_dostoewskij)\n",
    "print(len(s))\n",
    "s2 = set(sentenced_non_dostoewskij)\n",
    "print(len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 42\n"
     ]
    }
   ],
   "source": [
    "from libs.utils import load_transformer\n",
    "\n",
    "transformer = load_transformer('models/shm_c1')\n",
    "\n",
    "chars = transformer.tokens\n",
    "char_cats = len(chars)\n",
    "print('total chars:', char_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-52a0d0c7d724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdostoewskij_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdostoewskij_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mprint_len\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_dostoewskij_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "print_len = 200\n",
    "pos = np.random.randint(len(dostoewskij_text))\n",
    "print(dostoewskij_text[pos:pos+print_len])\n",
    "print('-' * 100)\n",
    "pos = np.random.randint(len(non_dostoewskij_text))\n",
    "print(non_dostoewskij_text[pos:pos+print_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_batches = len(dostoewskij_sentences)\n",
    "batch_size = 16\n",
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs.utils import pad\n",
    "\n",
    "# transform text into sequence of indices\n",
    "pad_idx = char_cats\n",
    "dostoewskij_indexes     = np.array([pad(transformer.transform(sent), max_len, pad_idx) for sent in dostoewskij_sentences])\n",
    "non_dostoewskij_indexes = np.array([pad(transformer.transform(sent), max_len, pad_idx) for sent in non_dostoewskij_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs.utils import split_data_into_correct_batches_for_stateful_rnnlit_data_into_correct_batches as split_data_into_correct_batches_sentences\n",
    "\n",
    "X, y = split_data_into_correct_batches_sentences(dostoewskij_indexes, non_dostoewskij_indexes, \n",
    "                                                 n_batches, max_len, make_equal_folding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269064728d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "a = plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats+1, int(char_cats / 1.5))(inp)\n",
    "    x = Conv1D(128, kernel_size=8, activation='relu', padding='same')(v) # None, 200, 64\n",
    "    x = Dropout(0.3)(BatchNormalization()(x))\n",
    "    x = MaxPooling1D(4, padding='same')(x) # None, 50, 64\n",
    "\n",
    "    x = Conv1D(128, kernel_size=8, activation='relu', padding='same')(x) # None, 50, 128\n",
    "    x = Dropout(0.3)(BatchNormalization()(x))\n",
    "    x = MaxPooling1D(2, padding='same')(x) # None, 25, 128\n",
    "\n",
    "    x = Conv1D(256, kernel_size=8, activation='relu', padding='same')(x) # None, 25, 256\n",
    "    x = Dropout(0.3)(BatchNormalization()(x))\n",
    "    x = MaxPooling1D(5, padding='same')(x) # None, 5, 256\n",
    "\n",
    "    h = Flatten()(x) # None, 5*256\n",
    "    y = Dense(2, activation='softmax')(h) # None, 512\n",
    "    model = Model(inp, y, name=\"char_cnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = create_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 28)           1204      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 200, 128)          28800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200, 128)          512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 50, 128)           131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 128)           512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 25, 256)           262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 25, 256)           1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 25, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 428,214\n",
      "Trainable params: 427,190\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1101/1101 [==============================] - 8s - loss: 1.3175 - acc: 0.5967     \n",
      "Epoch 1/1\n",
      "1101/1101 [==============================] - 1s - loss: 0.8151 - acc: 0.6876     \n",
      "Epoch 1/1\n",
      "1101/1101 [==============================] - 1s - loss: 0.6303 - acc: 0.7584     \n",
      "Epoch 1/1\n",
      "1101/1101 [==============================] - 1s - loss: 0.4942 - acc: 0.8156     \n",
      "Epoch 1/1\n",
      "1101/1101 [==============================] - 1s - loss: 0.3924 - acc: 0.8574     \n",
      "Epoch 1/1\n",
      "1101/1101 [==============================] - 1s - loss: 0.3253 - acc: 0.8874     \n",
      "Epoch 1/1\n",
      "1101/1101 [==============================] - 1s - loss: 0.2820 - acc: 0.9074     \n",
      "Epoch 1/1\n",
      "1101/1101 [==============================] - 1s - loss: 0.2034 - acc: 0.9237     \n"
     ]
    }
   ],
   "source": [
    "n_epochs = 8\n",
    "n_batches = len(dostoewskij_indexes)\n",
    "histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches_sentences(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(rnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.save('models/discriminator_style_rnn_model.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_char_cnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = Conv1D(filters=256, kernel_size=5, strides=2, activation='relu')(v)\n",
    "    h2 = Conv1D(filters=128, kernel_size=5, strides=2, activation='relu')(h1)\n",
    "    h3 = Conv1D(filters=64, kernel_size=5, strides=2, activation='relu')(h2)\n",
    "    r = Reshape((-1,))(h3)\n",
    "    y = Dense(2, activation='softmax')(r)\n",
    "    model = Model(inp, y, name=\"char_cnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnn = create_char_cnn()\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "history = cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1)#, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_epochs = 8\n",
    "n_batches = len(dostoewskij_indexes) // 30\n",
    "cnn_histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_epochs = 8\n",
    "cnn_histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_char_cnn_rnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = Conv1D(filters=256, kernel_size=3, strides=1, activation=sigmoid)(v)\n",
    "    h2 = GRU(256, stateful=False, return_sequences=True, unroll=True, implementation=0)(h1)\n",
    "    h3 = GRU(256, stateful=False, return_sequences=False, unroll=True, implementation=0)(h2)\n",
    "    y = Dense(2, activation='softmax')(h3)\n",
    "    model = Model(inp, y, name=\"char_cnn_rnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
