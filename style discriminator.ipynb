{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Input, Embedding, Reshape\n",
    "from keras.layers import LSTM, GRU, Conv1D\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.activations import sigmoid\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_non_dostoewskij_text():\n",
    "    dostoewskij_names = []\n",
    "    folder = 'data/Русская литература/Достоевский Ф.М.'\n",
    "    for item in os.listdir(folder):\n",
    "        itempath = os.path.join(folder, item)\n",
    "        #print(item)\n",
    "        if os.path.isfile(itempath):\n",
    "            dostoewskij_names.append(item.replace('.zip', ''))\n",
    "    res = ''\n",
    "    folder = 'data/texts/'\n",
    "    for item in os.listdir(folder):\n",
    "        itempath = os.path.join(folder, item)\n",
    "        if os.path.isfile(itempath) and not(item.replace('.txt', '') in dostoewskij_names):\n",
    "            with open(itempath, encoding='utf-8') as f:\n",
    "                res += f.read()\n",
    "    return res\n",
    "\n",
    "with open('data/dostoewskij_sent_split.txt', encoding='utf-8') as f:\n",
    "    dostoewskij_text = f.read().lower()\n",
    "non_dostoewskij_text = get_non_dostoewskij_text()\n",
    "\n",
    "with open('data/non_dostoewskij_texts.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(non_dostoewskij_text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def clear_text_from_rare_chars(whole_text, delete_enters = False):\n",
    "    whole_text = whole_text.replace('\\t', ' ')\n",
    "    whole_text = whole_text.replace('\\x15', '\\n')\n",
    "    whole_text = whole_text.replace('$', 'з')\n",
    "    whole_text = whole_text.replace('<', '')\n",
    "    whole_text = whole_text.replace('>', '')\n",
    "    whole_text = whole_text.replace('+-', 'е')\n",
    "    whole_text = whole_text.replace('\\\\', '.')\n",
    "    whole_text = whole_text.replace('~', ' ')\n",
    "    whole_text = whole_text.replace('\\x7f', ' ')\n",
    "    whole_text = whole_text.replace('\\xa0', ' ')\n",
    "    whole_text = whole_text.replace('\\xad', '')\n",
    "    whole_text = whole_text.replace('¤', 'О')\n",
    "    whole_text = whole_text.replace('¦', 'е')\n",
    "    whole_text = whole_text.replace('§', '')\n",
    "    whole_text = whole_text.replace('¶', '\\'')\n",
    "    whole_text = whole_text.replace('·', ' ')\n",
    "    whole_text = whole_text.replace('•', ' ')\n",
    "    if delete_enters:\n",
    "        whole_text = whole_text.replace('\\n', ' ')\n",
    "    while '  ' in whole_text:\n",
    "        whole_text = whole_text.replace('  ', ' ')\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.utils import text_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dostoewskij_length:\t 4911415\n",
      "non_dostoewskij_length:\t 173623913\n"
     ]
    }
   ],
   "source": [
    "with open('data/dostoewskij.txt', encoding='utf-8') as f:\n",
    "    dostoewskij_text = f.read().lower()\n",
    "with open('data/non_dostoewskij_texts.txt', encoding='utf-8') as f:\n",
    "    non_dostoewskij_text = f.read().lower()\n",
    "\n",
    "dostoewskij_text = text_preprocess(dostoewskij_text)\n",
    "non_dostoewskij_text = text_preprocess(non_dostoewskij_text)\n",
    "\n",
    "# dostoewskij_text = clear_text_from_rare_chars(dostoewskij_text, delete_enters=True)\n",
    "# non_dostoewskij_text = clear_text_from_rare_chars(non_dostoewskij_text, delete_enters=True)\n",
    "\n",
    "print('dostoewskij_length:\\t', len(dostoewskij_text))\n",
    "print('non_dostoewskij_length:\\t', len(non_dostoewskij_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 42\n"
     ]
    }
   ],
   "source": [
    "from libs.utils import load_transformer\n",
    "\n",
    "transformer = load_transformer('models/shm_c1')\n",
    "\n",
    "chars = transformer.tokens\n",
    "char_cats = len(chars)\n",
    "print('total chars:', char_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ержание ее хотя и форма прекрасная. содержание же \n",
      "\n",
      "неоспоримо. вот почему мы можем в радости предаться новой надежде: слишком \n",
      "\n",
      "очистился горизонт наш, слишком ярко всходит новое солнце наше... и если б \n",
      "\n",
      "только возможно было, чтоб мы все согласились и сошлись с народом в понимании: \n",
      "\n",
      "кого отселе считать человеком \"лучшим\", то с нынешнего лета, может быть, зачался \n",
      "\n",
      "бы новый период истории русской. \n",
      "\n",
      "\n",
      "\n",
      "ф. м. достоевский\n",
      "\n",
      "дневник писателя\n",
      "\n",
      "ежемесячное издание \n",
      "\n",
      " \n",
      "\n",
      "ноябрь \n",
      "\n",
      "глава первая \n",
      "\n",
      "кроткая фантастический \n",
      "\n",
      "рассказ \n",
      "\n",
      "\n",
      "\n",
      "от автора \n",
      "\n",
      "\n",
      "\n",
      "я прошу извинения у моих читателей, что на сей раз вместо \n",
      "\n",
      "\"дневника\" в обычной его форме даю лишь повесть. но я действительно занят был \n",
      "\n",
      "этой повестью большую часть месяца. во всяком случае прошу снисхождения \n",
      "\n",
      "читателей. \n",
      "\n",
      "теперь о самом рассказе. я озаглавил его \"фантастическим\", \n",
      "\n",
      "тогда как считаю его сам в высшей степени реальным. но фантастическое тут есть \n",
      "\n",
      "действительно, и именно в самой форме рассказа, что и нахожу нужным пояснить \n",
      "\n",
      "предварительно. \n",
      "\n",
      "дело в том, что это не рассказ и не записки. представьте себе \n",
      "\n",
      "мужа, у которого лежит на столе жена, самоубийца, несколько часов перед тем \n",
      "\n",
      "выбросившаяся из окошка. он в смятении и еще не успел собрать своих мыслей. он \n",
      "\n",
      "ходит по своим комнатам и старается осмыслить случившееся, \"собрать свои мысли в \n",
      "\n",
      "точку\". притом это закоренелый ипохондрик, из тех, что говорят сами с собою. вот \n",
      "\n",
      "он и говорит сам с собой, рассказывает дело, уясняет себе его. несмотря на \n",
      "\n",
      "кажущуюся последовательность речи, он несколько раз противуречит себе, и в \n",
      "\n",
      "логике и в чувствах. он и оправдывает себя, и обвиняет ее, и пускается в \n",
      "\n",
      "посторонние разъяснения: тут и грубость мысли и сердца, тут и глубокое чувство. \n",
      "\n",
      "мало-помалу он действительно уясняет себе дело и собирает \"мысли в точку\". ряд \n",
      "\n",
      "вызванных им воспоминаний неотразимо приводит его наконец к правде правда \n",
      "\n",
      "неотразимо возвышает его ум и сердце. к концу даже тон рассказа изменяется \n",
      "\n",
      "сравнительно с беспорядочным началом его. истина открыва\n",
      "----------------------------------------------------------------------------------------------------\n",
      "л шляпу и вышел из комнаты вместе с потугиным.\n",
      "\n",
      "     \n",
      "\n",
      "    они пришли в одну из лучших гостиниц бадена и спросили генеральшу ратмирову. швейцар сперва осведомился об их именах, потом тотчас отвечал, что \"     \" ,- и сам повел их по лестнице, сам постучал в дверь номера и доложил о них. \"  \" приняла их немедленно она была одна: муж ее отправился в кралсруэ для свидания с проезжавшим сановным тузом из \"влиятельных\".\n",
      "    ирина сидела за небольшим столиком и вышивала по канве, когда потугин с литвиновым переступили порог двери. она проворно бросила шитье в сторону, оттолкнула столик, встала выражение неподдельного удовольствия распространилось по ее лицу. на ней было утреннее, доверху закрытое платье прекрасные очертания плеч и рук сквозили через легкую ткань небрежно закрученная коса распустилась и падала низко на тонкую шею. ирина бросила потугину быстрый взгляд, шепнула \"\" и, протянув литвинову руку, любезно упрекнула его в забывчивости. \"а еще старый друг\",- прибавила она. литвинов начал было извиняться. \"с ,  \" ,- поспешно промолвила она и, с ласковым насилием отняв у него шляпу, заставила его сесть. потугин тоже сел, но тотчас же поднялся и, сказав, что у него есть безотлагательное дело и что он зайдет после обеда, стал раскланиваться. ирина снова бросила ему быстрый взгляд и дружески кивнула ему головой, но не удерживала его и, как только он исчез за портьеркой,с нетерпеливою живостью обратилась к литвинову.\n",
      "    - григорий михайлыч,- заговорила она по-русски своим мягким и звонким голосом,- вот мы одни наконец, и я могу сказать вам, что я очень рада нашей встрече, потому что она... она даст мне возможность... ирина посмотрела ему дрямо в лицо попросить у вас прощения. литвинов невольно вздрогнул. такого быстрого натиска он не ожидал. он не ожидал, что она сама наведет речь на прежние времена.\n",
      "    - в чем... прощения...- пробормотал он.\n",
      "    ирина покраснела.\n",
      "    - в чем?.. вы знаете, в чем,- промолвила она и слегка отвернулась.- я была виновата перед вами, григори\n"
     ]
    }
   ],
   "source": [
    "print_len = 2000\n",
    "pos = np.random.randint(len(dostoewskij_text))\n",
    "print(dostoewskij_text[pos:pos+print_len])\n",
    "print('-' * 100)\n",
    "pos = np.random.randint(len(non_dostoewskij_text))\n",
    "print(non_dostoewskij_text[pos:pos+print_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = len(dostoewskij_text) // 3000\n",
    "batch_size = 16\n",
    "#n_batches -= n_batches % batch_size\n",
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform text into sequence of indices\n",
    "dostoewskij_indexes        = transformer.transform(dostoewskij_text)\n",
    "non_dostoewskij_indexes = transformer.transform(non_dostoewskij_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_into_correct_batches(text1_indexes, text2_indexes, make_equal_folding = True):\n",
    "    prime_number = 2147483647\n",
    "    \n",
    "    X = np.zeros((n_batches, max_len), dtype=np.int64)\n",
    "    Y = np.zeros((n_batches,), dtype=np.int64)\n",
    "    \n",
    "    choose_from_first = True\n",
    "    index1 = 0\n",
    "    index2 = 0\n",
    "    for i in range(n_batches):\n",
    "        if make_equal_folding:\n",
    "            if choose_from_first:\n",
    "                index1 = (index1 + prime_number) % (len(text1_indexes) - max_len + 1)\n",
    "                X[i, :] = text1_indexes[index1:index1+max_len]\n",
    "                Y[i] = 0\n",
    "            else:\n",
    "                index2 = (index2 + prime_number) % (len(text2_indexes) - max_len + 1)\n",
    "                X[i, :] = text2_indexes[index2:index2+max_len]\n",
    "                Y[i] = 1\n",
    "                \n",
    "            choose_from_first = not choose_from_first\n",
    "        else:\n",
    "            index1 = (index1 + prime_number) % (len(text1_indexes) + len(text2_indexes) - 2*max_len + 2)\n",
    "            if index1 < len(text1_indexes) - max_len + 1:\n",
    "                X[i, :] = text1_indexes[index1:index1 + max_len]\n",
    "                Y[i] = 0\n",
    "            else:\n",
    "                index2 = index1 - (len(text1_indexes) - max_len + 1)\n",
    "                X[i, :] = text2_indexes[index2:index2 + max_len]\n",
    "                Y[i] = 1\n",
    "    return X, Y\n",
    "\n",
    "X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng16SGmfQS1LjDHpJapxBL0mN+79UfDbqZaQ2qwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14f4182b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "a = plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_char_rnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = GRU(256, stateful=False, return_sequences=True, unroll=True, implementation=0)(v)\n",
    "    h2 = GRU(256, stateful=False, return_sequences=False, unroll=True, implementation=0)(h1)\n",
    "    y = Dense(2, activation='softmax')(h2)\n",
    "    model = Model(inp, y, name=\"char_rnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = create_char_rnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 28)           1176      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 200, 256)          218880    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               393984    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 614,554\n",
      "Trainable params: 614,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tb = TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "history = rnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1)#, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 8\n",
    "histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(rnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.save('models/discriminator_style_rnn_model.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_char_cnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = Conv1D(filters=256, kernel_size=5, strides=2, activation='relu')(v)\n",
    "    h2 = Conv1D(filters=128, kernel_size=5, strides=2, activation='relu')(h1)\n",
    "    h3 = Conv1D(filters=64, kernel_size=5, strides=2, activation='relu')(h2)\n",
    "    r = Reshape((-1,))(h3)\n",
    "    y = Dense(2, activation='softmax')(r)\n",
    "    model = Model(inp, y, name=\"char_cnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnn = create_char_cnn()\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "history = cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1)#, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_epochs = 8\n",
    "n_batches = len(dostoewskij_indexes) // 30\n",
    "cnn_histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_epochs = 8\n",
    "cnn_histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_char_cnn_rnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = Conv1D(filters=256, kernel_size=3, strides=1, activation=sigmoid)(v)\n",
    "    h2 = GRU(256, stateful=False, return_sequences=True, unroll=True, implementation=0)(h1)\n",
    "    h3 = GRU(256, stateful=False, return_sequences=False, unroll=True, implementation=0)(h2)\n",
    "    y = Dense(2, activation='softmax')(h3)\n",
    "    model = Model(inp, y, name=\"char_cnn_rnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
