{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Input, Embedding, Reshape, MaxPooling1D, Conv1D\n",
    "from keras.layers import LSTM, GRU, Conv1D\n",
    "from keras.layers import Dropout, BatchNormalization, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.activations import sigmoid\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_non_dostoewskij_text():\n",
    "    dostoewskij_names = []\n",
    "    folder = 'data/Русская литература/Достоевский Ф.М.'\n",
    "    for item in os.listdir(folder):\n",
    "        itempath = os.path.join(folder, item)\n",
    "        #print(item)\n",
    "        if os.path.isfile(itempath):\n",
    "            dostoewskij_names.append(item.replace('.zip', ''))\n",
    "    res = ''\n",
    "    folder = 'data/texts/'\n",
    "    for item in os.listdir(folder):\n",
    "        itempath = os.path.join(folder, item)\n",
    "        if os.path.isfile(itempath) and not(item.replace('.txt', '') in dostoewskij_names):\n",
    "            with open(itempath, encoding='utf-8') as f:\n",
    "                res += f.read()\n",
    "    return res\n",
    "\n",
    "with open('data/dostoewskij_sent_split.txt', encoding='utf-8') as f:\n",
    "    dostoewskij_text = f.read().lower()\n",
    "non_dostoewskij_text = get_non_dostoewskij_text()\n",
    "\n",
    "with open('data/non_dostoewskij_texts.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(non_dostoewskij_text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def clear_text_from_rare_chars(whole_text, delete_enters = False):\n",
    "    whole_text = whole_text.replace('\\t', ' ')\n",
    "    whole_text = whole_text.replace('\\x15', '\\n')\n",
    "    whole_text = whole_text.replace('$', 'з')\n",
    "    whole_text = whole_text.replace('<', '')\n",
    "    whole_text = whole_text.replace('>', '')\n",
    "    whole_text = whole_text.replace('+-', 'е')\n",
    "    whole_text = whole_text.replace('\\\\', '.')\n",
    "    whole_text = whole_text.replace('~', ' ')\n",
    "    whole_text = whole_text.replace('\\x7f', ' ')\n",
    "    whole_text = whole_text.replace('\\xa0', ' ')\n",
    "    whole_text = whole_text.replace('\\xad', '')\n",
    "    whole_text = whole_text.replace('¤', 'О')\n",
    "    whole_text = whole_text.replace('¦', 'е')\n",
    "    whole_text = whole_text.replace('§', '')\n",
    "    whole_text = whole_text.replace('¶', '\\'')\n",
    "    whole_text = whole_text.replace('·', ' ')\n",
    "    whole_text = whole_text.replace('•', ' ')\n",
    "    if delete_enters:\n",
    "        whole_text = whole_text.replace('\\n', ' ')\n",
    "    while '  ' in whole_text:\n",
    "        whole_text = whole_text.replace('  ', ' ')\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs.utils import text_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dostoewskij_length:\t 4911415\n",
      "non_dostoewskij_length:\t 173623913\n"
     ]
    }
   ],
   "source": [
    "with open('data/dostoewskij.txt', encoding='utf-8') as f:\n",
    "    dostoewskij_text = f.read().lower()\n",
    "with open('data/non_dostoewskij_texts.txt', encoding='utf-8') as f:\n",
    "    non_dostoewskij_text = f.read().lower()\n",
    "\n",
    "dostoewskij_text = text_preprocess(dostoewskij_text)\n",
    "non_dostoewskij_text = text_preprocess(non_dostoewskij_text)\n",
    "\n",
    "# dostoewskij_text = clear_text_from_rare_chars(dostoewskij_text, delete_enters=True)\n",
    "# non_dostoewskij_text = clear_text_from_rare_chars(non_dostoewskij_text, delete_enters=True)\n",
    "\n",
    "print('dostoewskij_length:\\t', len(dostoewskij_text))\n",
    "print('non_dostoewskij_length:\\t', len(non_dostoewskij_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 42\n"
     ]
    }
   ],
   "source": [
    "from libs.utils import load_transformer\n",
    "\n",
    "transformer = load_transformer('models/shm_c1')\n",
    "\n",
    "chars = transformer.tokens\n",
    "char_cats = len(chars)\n",
    "print('total chars:', char_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "\"золотым промыслом\" и пользуясь неопытностью и пороками эксплуатируемого \n",
      "\n",
      "племени. представьте же себе, когда я прочел это, мне тотчас же вспомнилось, что \n",
      "\n",
      "мне еще пять лет тому приходило это самое на ум, именно то, что вот ведь негры \n",
      "\n",
      "от рабовладельцев теперь освобождены, а ведь им не уцелеть, потому что на эту \n",
      "\n",
      "свежую жертвочку как раз набросятся евреи, которых столь много на свете. подумал \n",
      "\n",
      "я это, и, уверяю вас, несколько раз потом в этот срок мне вспадало на мысль: \"да \n",
      "\n",
      "что же там ничего об евреях не слышно, что в газетах не пишут, ведь эти негры \n",
      "\n",
      "евреям клад, неужели пропустят?\" и вот дождался, написали в газетах, прочел. а \n",
      "\n",
      "дней десять тому назад прочел в \"новом времени\"   корреспонденцию из \n",
      "\n",
      "ковно, прехарактернейшую: \"дескать, до того набросились там евреи на местное \n",
      "\n",
      "литовское население, что чуть не сгубили всех водкой, и только ксендзы спасли \n",
      "\n",
      "бедных опившихся, угрожая им муками ада и устраивая между ними общества \n",
      "\n",
      "трезвости\". просвещенный корреспондент, правда, сильно краснеет за свое \n",
      "\n",
      "население, до сих пор верующее в ксендзов и в муки ада, но он сообщает при этом, \n",
      "\n",
      "что поднялись вслед за ксендзами и просвещенные местные экономисты, начали \n",
      "\n",
      "устраивать сельские банки, именно чтобы спасти народ от процентщика-еврея, и \n",
      "\n",
      "сельские рынки, чтобы можно было \"бедной трудящейся массе\" получать предметы \n",
      "\n",
      "первой потребности по настоящей цене, а не по той, которую назначает еврей. ну, \n",
      "\n",
      "вот я это вс прочел и знаю, что мне в один миг закричат, что вс это ничего не \n",
      "\n",
      "доказывает, что это от того, что евреи сами угнетены, сами бедны, и что вс это \n",
      "\n",
      "лишь \"борьба за существование\", что только глупец разобрать этого не может, и не \n",
      "\n",
      "будь евреи так сами бедны, а, напротив, разбогатей они, то мигом показали бы \n",
      "\n",
      "себя с самой гуманной стороны, так что мир бы весь удивили. но ведь, конечно, \n",
      "\n",
      "все эти негры и литовцы еще беднее евреев, выжимающих из них соки, а ведь те \n",
      "\n",
      "прочтите-ка корреспонденцию гнушаются такой торговлей, на которую так падок \n",
      "\n",
      "еврей во-втор\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ямо обратилась к зятю.\n",
      "    - петр григорьевич, выпей водочки и скушай что-нибудь. не побрезгуй хоть ты-то нашим хлебом-солью.\n",
      "    в последних словах ее послышалось что-то зловещее для надины. но петр григорьевич, ничего этого, конечно, не понявший, положил себе не без удовольствия на тарелку два куска пирога и, отправившись в угол, начал там смиренно есть.\n",
      "    - саша, покушай, друг мой! - обратилась биби к александру и нарочно необыкновенно ласковым голосом.\n",
      "    студент тоже, со свойственным его возрасту аппетитом, наложив себе на тарелку не совсем свежей печенки, сухой икры и трехгодовалых рыжиков, принялся все это уничтожать. надежда павловна и соня намазали себе только немного масла на хлеб.\n",
      "    биби решительно шипела.\n",
      "    - виктор ваш скоро должен выйти в офицеры, - отнеслась она к сестре.\n",
      "    при этом уж надежда павловна вспыхнула биби всегда колола ее тем, что в отношении к сыновьям она дурно исполняет свои обязанности.\n",
      "    - да, если выдержит экзамен, - отвечала она коротко, чтобы прекратить этот разговор.\n",
      "    - я получила от него довольно странное письмо, - продолжала биби с расстановкой. - вот оно, не хочешь ли полюбопытствовать, - прибавила она, вынимая из кармана и подавая надежде павловне кругом исписанный лист почтовой бумаги. та взяла его дрожащею и сконфуженною рукой. она заранее предчувствовала, что тут заключается но, с продолжением чтения, гневный румянец все больше и больше выступал на ее щеках. молодой басардин, несмотря на кадетский почерк и обильное число грамматических ошибок, владел, как видно, пером. \"дражайшая тетушка! - писал он: - я еще помню вас маленьким и драгоценный образ ваш навсегда сохранил в моей памяти. простите великодушно, почтеннейшая тетушка, что никогда не писал к вам. причиной тому мои родители, которые отвергнули меня еще от груди матери, но теперь я скоро буду офицер и хочу сам себе пробить дорогу в жизни или умереть на поле чести\"...\n",
      "    - боже, как он глуп! - почти простонала бедная мать.\n",
      "    \"я, вероятно, по успехам в \n"
     ]
    }
   ],
   "source": [
    "print_len = 2000\n",
    "pos = np.random.randint(len(dostoewskij_text))\n",
    "print(dostoewskij_text[pos:pos+print_len])\n",
    "print('-' * 100)\n",
    "pos = np.random.randint(len(non_dostoewskij_text))\n",
    "print(non_dostoewskij_text[pos:pos+print_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_batches = len(dostoewskij_text) // 30\n",
    "batch_size = 16\n",
    "#n_batches -= n_batches % batch_size\n",
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform text into sequence of indices\n",
    "dostoewskij_indexes        = transformer.transform(dostoewskij_text)\n",
    "non_dostoewskij_indexes = transformer.transform(non_dostoewskij_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data_into_correct_batches(text1_indexes, text2_indexes, make_equal_folding = True):\n",
    "    prime_number = 2147483647\n",
    "    \n",
    "    X = np.zeros((n_batches, max_len), dtype=np.int64)\n",
    "    Y = np.zeros((n_batches,), dtype=np.int64)\n",
    "    \n",
    "    choose_from_first = True\n",
    "    index1 = 0\n",
    "    index2 = 0\n",
    "    for i in range(n_batches):\n",
    "        if make_equal_folding:\n",
    "            if choose_from_first:\n",
    "                index1 = (index1 + prime_number) % (len(text1_indexes) - max_len + 1)\n",
    "                X[i, :] = text1_indexes[index1:index1+max_len]\n",
    "                Y[i] = 0\n",
    "            else:\n",
    "                index2 = (index2 + prime_number) % (len(text2_indexes) - max_len + 1)\n",
    "                X[i, :] = text2_indexes[index2:index2+max_len]\n",
    "                Y[i] = 1\n",
    "                \n",
    "            choose_from_first = not choose_from_first\n",
    "        else:\n",
    "            index1 = (index1 + prime_number) % (len(text1_indexes) + len(text2_indexes) - 2*max_len + 2)\n",
    "            if index1 < len(text1_indexes) - max_len + 1:\n",
    "                X[i, :] = text1_indexes[index1:index1 + max_len]\n",
    "                Y[i] = 0\n",
    "            else:\n",
    "                index2 = index1 - (len(text1_indexes) - max_len + 1)\n",
    "                X[i, :] = text2_indexes[index2:index2 + max_len]\n",
    "                Y[i] = 1\n",
    "    return X, Y\n",
    "\n",
    "X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19480017908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "a = plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_char_rnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats+1, int(char_cats / 1.5))(inp)\n",
    "    h1 = GRU(256, stateful=False, return_sequences=True, unroll=True, implementation=0)(v)\n",
    "    h2 = GRU(256, stateful=False, return_sequences=False, unroll=True, implementation=0)(h1)\n",
    "    y = Dense(2, activation='softmax')(h2)\n",
    "    model = Model(inp, y, name=\"char_rnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats+1, int(char_cats / 1.5))(inp)\n",
    "    x = Conv1D(128, kernel_size=8, activation='relu', padding='same')(v) # None, 200, 64\n",
    "    x = Dropout(0.3)(BatchNormalization()(x))\n",
    "    x = MaxPooling1D(4, padding='same')(x) # None, 50, 64\n",
    "\n",
    "    x = Conv1D(128, kernel_size=8, activation='relu', padding='same')(x) # None, 50, 128\n",
    "    x = Dropout(0.3)(BatchNormalization()(x))\n",
    "    x = MaxPooling1D(2, padding='same')(x) # None, 25, 128\n",
    "\n",
    "    x = Conv1D(256, kernel_size=8, activation='relu', padding='same')(x) # None, 25, 256\n",
    "    x = Dropout(0.3)(BatchNormalization()(x))\n",
    "    x = MaxPooling1D(5, padding='same')(x) # None, 5, 256\n",
    "\n",
    "    h = Flatten()(x) # None, 5*256\n",
    "    y = Dense(2, activation='softmax')(h) # None, 512\n",
    "    model = Model(inp, y, name=\"char_cnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = create_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 28)           1204      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 200, 128)          28800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200, 128)          512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 50, 128)           131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 128)           512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 25, 256)           262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 25, 256)           1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 25, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 428,214\n",
      "Trainable params: 427,190\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tb = TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "163713/163713 [==============================] - 110s - loss: 0.2649 - acc: 0.8793   \n"
     ]
    }
   ],
   "source": [
    "history = rnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1)#, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "163713/163713 [==============================] - 108s - loss: 0.2098 - acc: 0.9076   \n",
      "Epoch 1/1\n",
      "163713/163713 [==============================] - 107s - loss: 0.1895 - acc: 0.9177   \n",
      "Epoch 1/1\n",
      "163713/163713 [==============================] - 112s - loss: 0.1754 - acc: 0.9253   \n",
      "Epoch 1/1\n",
      "163713/163713 [==============================] - 108s - loss: 0.1667 - acc: 0.9296   \n",
      "Epoch 1/1\n",
      "163713/163713 [==============================] - 108s - loss: 0.1597 - acc: 0.9342   \n",
      "Epoch 1/1\n",
      "163713/163713 [==============================] - 107s - loss: 0.1508 - acc: 0.9380   \n",
      "Epoch 1/1\n",
      "163713/163713 [==============================] - 110s - loss: 0.1442 - acc: 0.9406   \n",
      "Epoch 1/1\n",
      "163713/163713 [==============================] - 108s - loss: 0.1392 - acc: 0.9428   \n"
     ]
    }
   ],
   "source": [
    "n_epochs = 8\n",
    "histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(rnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.save('models/discriminator_style_rnn_model.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_char_cnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = Conv1D(filters=256, kernel_size=5, strides=2, activation='relu')(v)\n",
    "    h2 = Conv1D(filters=128, kernel_size=5, strides=2, activation='relu')(h1)\n",
    "    h3 = Conv1D(filters=64, kernel_size=5, strides=2, activation='relu')(h2)\n",
    "    r = Reshape((-1,))(h3)\n",
    "    y = Dense(2, activation='softmax')(r)\n",
    "    model = Model(inp, y, name=\"char_cnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnn = create_char_cnn()\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "history = cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1)#, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_epochs = 8\n",
    "n_batches = len(dostoewskij_indexes) // 30\n",
    "cnn_histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_epochs = 8\n",
    "cnn_histories = []\n",
    "for epoch in range(n_epochs):\n",
    "    X, y = split_data_into_correct_batches(dostoewskij_indexes, non_dostoewskij_indexes, make_equal_folding=True)\n",
    "    histories.append(cnn.fit(X, y, batch_size=batch_size, shuffle=True, epochs=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_char_cnn_rnn():\n",
    "    inp = Input(shape=(max_len,), dtype=\"int32\")\n",
    "    v = Embedding(char_cats, int(char_cats / 1.5))(inp)\n",
    "    h1 = Conv1D(filters=256, kernel_size=3, strides=1, activation=sigmoid)(v)\n",
    "    h2 = GRU(256, stateful=False, return_sequences=True, unroll=True, implementation=0)(h1)\n",
    "    h3 = GRU(256, stateful=False, return_sequences=False, unroll=True, implementation=0)(h2)\n",
    "    y = Dense(2, activation='softmax')(h3)\n",
    "    model = Model(inp, y, name=\"char_cnn_rnn\")\n",
    "    model.compile(optimizer=RMSprop(), loss=sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
